# Configuration for Cog ⚙️
# Reference: https://cog.run/yaml

build:
  # set to true if your model requires a GPU
  gpu: false

  # a list of ubuntu apt packages to install
  system_packages:
    - "libopenblas-dev"
    - "cmake"
    - "clang"
    - "pkg-config"
    - "git"

  # python version in the form '3.11' or '3.11.4'
  python_version: "3.11"

  # a list of packages in the format <package-name>==<version>
  python_packages:
    - "python-json-logger"

  # commands run after the environment is setup
  run:
    - 'CC=/usr/bin/clang CXX=/usr/bin/clang++ CMAKE_ARGS="-DLLAMA_BLAS=ON -DLLAMA_BLAS_VENDOR=OpenBLAS" pip install llama-cpp-python'
image: "r8.im/libklein/tunecraft.io"
# predict.py defines how predictions are run on your model
predict: "predict.py:Predictor"
